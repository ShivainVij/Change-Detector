{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee7bf27",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651bba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToTrainImages = \"D:/Perfect Shape Images/Train/\"\n",
    "pathToTestImages = \"D:/Perfect Shape Images/Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce14cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdbfdd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80baecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96424c7",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4120be",
   "metadata": {},
   "source": [
    "### Create Dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f85d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(Dataset):\n",
    "    \"\"\"Shape dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample. -> Not used\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                str(idx)+ '.jpg')\n",
    "        image = cv2.imread(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        #perfect square should yield strongest activation which will be 1\n",
    "        return image, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73dd550",
   "metadata": {},
   "source": [
    "### Set Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15a128",
   "metadata": {},
   "source": [
    "### Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be2e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ShapeDataset(pathToTrainImages, transform)\n",
    "testset = ShapeDataset(pathToTrainImages, transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d9570",
   "metadata": {},
   "source": [
    "## View Sample Images + Test Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d5cba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d31ab90808>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()\n",
    "\n",
    "npimg = np.transpose(images[0], (1, 2, 0))\n",
    "\n",
    "plt.imshow(npimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbde6af",
   "metadata": {},
   "source": [
    "## Create CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feeb0fe",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94edd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 10)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 10)\n",
    "        self.fc1 = nn.Linear(529984, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c42e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SquareNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ef733",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0b8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05e5e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 0.000\n",
      "[1,    10] loss: 0.000\n",
      "[1,    15] loss: 0.000\n",
      "[1,    20] loss: 0.000\n",
      "[1,    25] loss: 0.000\n",
      "[2,     5] loss: 0.000\n",
      "[2,    10] loss: 0.000\n",
      "[2,    15] loss: 0.000\n",
      "[2,    20] loss: 0.000\n",
      "[2,    25] loss: 0.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        labels = labels[...,None]\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c317a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37e681bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4607],\n",
       "        [0.4617],\n",
       "        [0.4606],\n",
       "        [0.4600]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a9ff402",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = torch.Tensor(cv2.imread(pathToTestImages + \"rectangle.jpg\"))\n",
    "rec = rec[...,None]\n",
    "rec = np.transpose(rec, (3, 2, 0, 1))\n",
    "output = net(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc5b1909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9253]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
